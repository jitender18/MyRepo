{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "from pyspark import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "ratings_rdd = sc.textFile('/Users/jitu/Documents/Fall/Big Data/Assignments/ml-latest-small/ratings.csv').map(lambda line: line.split(\",\")[:-1])\n",
    "\n",
    "df = ratings_rdd.toDF(['user_ID','movie_ID','ratings'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-------+\n",
      "|user_ID|movie_ID|ratings|\n",
      "+-------+--------+-------+\n",
      "| userId| movieId| rating|\n",
      "|      1|      31|    2.5|\n",
      "|      1|    1029|    3.0|\n",
      "|      1|    1061|    3.0|\n",
      "|      1|    1129|    2.0|\n",
      "|      1|    1172|    4.0|\n",
      "|      1|    1263|    2.0|\n",
      "|      1|    1287|    2.0|\n",
      "|      1|    1293|    2.0|\n",
      "|      1|    1339|    3.5|\n",
      "|      1|    1343|    2.0|\n",
      "|      1|    1371|    2.5|\n",
      "|      1|    1405|    1.0|\n",
      "|      1|    1953|    4.0|\n",
      "|      1|    2105|    4.0|\n",
      "|      1|    2150|    3.0|\n",
      "|      1|    2193|    2.0|\n",
      "|      1|    2294|    2.0|\n",
      "|      1|    2455|    2.5|\n",
      "|      1|    2968|    1.0|\n",
      "+-------+--------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "given_userID = 1\n",
    "given_movieID = '31'\n",
    "avgrating = '3.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_rdd = sc.textFile('/Users/jitu/Documents/Fall/Big Data/Assignments/ml-latest-small/movies.csv').map(lambda line: line.split(\",\")[:2])\n",
    "\n",
    "df1 = movies_rdd.toDF(['movie_ID','movie_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|movie_ID|          movie_name|\n",
      "+--------+--------------------+\n",
      "| movieId|               title|\n",
      "|       1|    Toy Story (1995)|\n",
      "|       2|      Jumanji (1995)|\n",
      "|       3|Grumpier Old Men ...|\n",
      "|       4|Waiting to Exhale...|\n",
      "|       5|Father of the Bri...|\n",
      "|       6|         Heat (1995)|\n",
      "|       7|      Sabrina (1995)|\n",
      "|       8| Tom and Huck (1995)|\n",
      "|       9| Sudden Death (1995)|\n",
      "|      10|    GoldenEye (1995)|\n",
      "|      11| \"American President|\n",
      "|      12|Dracula: Dead and...|\n",
      "|      13|        Balto (1995)|\n",
      "|      14|        Nixon (1995)|\n",
      "|      15|Cutthroat Island ...|\n",
      "|      16|       Casino (1995)|\n",
      "|      17|Sense and Sensibi...|\n",
      "|      18|   Four Rooms (1995)|\n",
      "|      19|Ace Ventura: When...|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"movie_ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|movie_ID|          movie_name|\n",
      "+--------+--------------------+\n",
      "|       1|    Toy Story (1995)|\n",
      "|       2|      Jumanji (1995)|\n",
      "|       3|Grumpier Old Men ...|\n",
      "|       4|Waiting to Exhale...|\n",
      "|       5|Father of the Bri...|\n",
      "|       6|         Heat (1995)|\n",
      "|       7|      Sabrina (1995)|\n",
      "|       8| Tom and Huck (1995)|\n",
      "|       9| Sudden Death (1995)|\n",
      "|      10|    GoldenEye (1995)|\n",
      "|      11| \"American President|\n",
      "|      12|Dracula: Dead and...|\n",
      "|      13|        Balto (1995)|\n",
      "|      14|        Nixon (1995)|\n",
      "|      15|Cutthroat Island ...|\n",
      "|      16|       Casino (1995)|\n",
      "|      17|Sense and Sensibi...|\n",
      "|      18|   Four Rooms (1995)|\n",
      "|      19|Ace Ventura: When...|\n",
      "|      20|  Money Train (1995)|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.createOrReplaceTempView(\"all_movies\")\n",
    "movies = spark.sql(\"SELECT * FROM all_movies where movie_ID>0\")\n",
    "movies.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-------+\n",
      "|user_ID|movie_ID|ratings|\n",
      "+-------+--------+-------+\n",
      "|      1|      31|    2.5|\n",
      "|      1|    1029|    3.0|\n",
      "|      1|    1061|    3.0|\n",
      "|      1|    1129|    2.0|\n",
      "|      1|    1172|    4.0|\n",
      "|      1|    1263|    2.0|\n",
      "|      1|    1287|    2.0|\n",
      "|      1|    1293|    2.0|\n",
      "|      1|    1339|    3.5|\n",
      "|      1|    1343|    2.0|\n",
      "|      1|    1371|    2.5|\n",
      "|      1|    1405|    1.0|\n",
      "|      1|    1953|    4.0|\n",
      "|      1|    2105|    4.0|\n",
      "|      1|    2150|    3.0|\n",
      "|      1|    2193|    2.0|\n",
      "|      1|    2294|    2.0|\n",
      "|      1|    2455|    2.5|\n",
      "|      1|    2968|    1.0|\n",
      "|      1|    3671|    3.0|\n",
      "+-------+--------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings = spark.sql(\"SELECT * FROM movie_ratings where movie_ID>0\")\n",
    "ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|count(DISTINCT user_ID)|\n",
      "+-----------------------+\n",
      "|                     42|\n",
      "+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql1 = spark.sql(\"SELECT count(distinct(movie_ratings.user_ID)) FROM movie_ratings where movie_ratings.user_ID in (SELECT user_ID FROM movie_ratings where movie_ratings.movie_ID = '%s')\" %given_movieID)\n",
    "sql1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|movie_ID|         avgrating|\n",
      "+--------+------------------+\n",
      "|    2294|3.2735849056603774|\n",
      "|     296| 4.256172839506172|\n",
      "|    3210|3.6153846153846154|\n",
      "|   88140| 3.659090909090909|\n",
      "|  115713|3.9423076923076925|\n",
      "|   27317|              3.75|\n",
      "|    1090|3.9338235294117645|\n",
      "|    3959|            3.4375|\n",
      "|    3606| 4.111111111111111|\n",
      "|    6731|              3.25|\n",
      "|   89864|3.6923076923076925|\n",
      "|  106022|               4.0|\n",
      "|   48738| 4.033333333333333|\n",
      "|    2069|3.7777777777777777|\n",
      "|    3414|               4.0|\n",
      "|    4821| 4.333333333333333|\n",
      "|    1572| 4.166666666666667|\n",
      "|     691| 3.357142857142857|\n",
      "|   50802|              3.25|\n",
      "|   26082|               4.5|\n",
      "+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_ratings = spark.sql(\"select movie_ID, avg(ratings) as avgrating from movie_ratings group by movie_ID having avg(ratings)>3.0\")\n",
    "avg_ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+-----+\n",
      "|movie_ID|              AVG|count|\n",
      "+--------+-----------------+-----+\n",
      "|     116|             4.75|    6|\n",
      "|    7116|              4.7|    5|\n",
      "|     178|              4.7|    5|\n",
      "|    1939|4.636363636363637|   11|\n",
      "|    5114|              4.6|    5|\n",
      "|    2924|4.583333333333333|    6|\n",
      "|    3469|4.541666666666667|   12|\n",
      "|   52767|              4.5|    5|\n",
      "|    7075|              4.5|    5|\n",
      "|     858|           4.4875|  200|\n",
      "|     318|4.487138263665595|  311|\n",
      "|    1948|4.458333333333333|   12|\n",
      "|    8132|4.454545454545454|   11|\n",
      "|    1945|4.448275862068965|   29|\n",
      "|    3167|           4.4375|    8|\n",
      "|    3310|           4.4375|    8|\n",
      "|     926|4.434210526315789|   38|\n",
      "|     969|             4.42|   50|\n",
      "|   77658|4.416666666666667|    6|\n",
      "|    3035|4.411764705882353|   17|\n",
      "+--------+-----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_movies = spark.sql(\"select movie_ID, avg(ratings) as AVG, count(movie_ID) as count from movie_ratings where movie_ID in (SELECT distinct(movie_ID) FROM movie_ratings where user_ID in (SELECT user_ID FROM movie_ratings where movie_ID = '%s' and user_ID not in ('%s'))) group by movie_ID having count >=5 order by AVG desc\" %(given_movieID, given_userID))\n",
    "users_movies.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------------+\n",
      "|movie_ID|          movie_name|              AVG|\n",
      "+--------+--------------------+-----------------+\n",
      "|     116|Anne Frank Rememb...|             4.75|\n",
      "|     178|Love & Human Rema...|              4.7|\n",
      "|    7116|Diabolique (Les d...|              4.7|\n",
      "|    1939|\"Best Years of Ou...|4.636363636363637|\n",
      "|    5114|\"Bad and the Beau...|              4.6|\n",
      "+--------+--------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final = users_movies.join(movies, users_movies.movie_ID==movies.movie_ID).select(users_movies.movie_ID, movies.movie_name, users_movies.AVG).orderBy(users_movies.AVG.desc())\n",
    "final.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
